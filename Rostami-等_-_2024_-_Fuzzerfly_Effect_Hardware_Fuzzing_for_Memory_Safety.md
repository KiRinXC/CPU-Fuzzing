

![0196f2ce-ab6a-762f-b736-bd531132bc1c_0_75_244_1634_410_0.jpg](images/0196f2ce-ab6a-762f-b736-bd531132bc1c_0_75_244_1634_410_0.jpg)

Hardware Fuzzing for Memory Safety

Mohamadreza Rostami ${}^{1}$ Technical University of Darmstadt Chen Chen ${}^{\circledR }$ and Rahul Kande ${}^{\circledR }$ | Texas A&M University Huimin Li ${}^{ \oplus  }$ Delft University of Technology Jeyavijayan Rajendran ${}^{\circledR }$ | Texas A&M University Ahmad-Reza Sadeghi ${}^{1}$ Technical University of Darmstadt

Hardware-level memory vulnerabilities severely threaten computing systems. However, hardware patching is inefficient or difficult postfabrication. We investigate the effectiveness of hardware fuzzing in detecting hardware memory vulnerabilities and highlight challenges and potential future research directions to enhance hardware fuzzing for memory safety.

Memory safety is foundational to the overall security of computing systems and becomes a significant risk when compromised, particularly impacting the integrity of critical systems. The increasing complexity of software and hardware systems and the discovery of novel and severe cross-layer attacks based on software-exploitable hardware vulnerabilities have highlighted the multifaceted nature of memory safety. Cross-layer attacks bring to light the limitations inherent in software-based memory safety approaches. They underscore that safeguarding memory goes beyond countering traditional software memory corruption attacks, such as user-after-free, out-of-bounds access, and heap/stack overflow, which typically stem from operating system flaws or software implementations.

The recent hardware vulnerabilities, such as Zenbleed ${}^{1}$ and Downfall, ${}^{2}$ challenge the widely held belief that a secure system can be achieved exclusively through secure software. These vulnerabilities illustrate that attackers can exploit vulnerabilities in the underlying hardware even if the software is carefully developed to protect sensitive data. These attacks exploit inherent microarchitectural flaws in modern processors to comprise sensitive information even within secure software or in the presence of software-based defenses. Moreover, vulnerabilities like Zombieload and Foreshadow-NG demonstrate that even cutting-edge hardware architectures with advanced protection mechanisms like Intel Software Guard Extension can succumb to unforeseen attack vectors. ${}^{1,2}$

The growing need for high-performance hardware has led to the incorporation of advanced optimization features in processors, such as speculative execution and special buffers, and the development of systems on chip (SoCs) with dedicated special-purpose processing units, e.g., artificial intelligence (AI) coprocessors, crypto coprocessors, and on-chip GPUs. Integrating new complex features and components into processors and SoCs has significantly broadened the potential attack surface for adversaries, extending memory safety concerns beyond traditional consideration of dynamic random-access memory (DRAM) and cache since they encompass microarchitectural and architectural resources within the processor and SoC, including general-purpose registers, vector extension registers, control/status registers, and SoC memory-mapped buffers and registers.

---

Digital Object Identifier 10.1109/MSEC.2024.3365070

Date of publication 7 March 2024; date of current version: 17 July 2024.

---

Hence, there is a need for effective tools and methodologies to identify and mitigate such memory safety issues in hardware designs. Existing hardware mitigation approaches against memory vulnerabilities can be categorized into

1. mitigation approaches based on architectural vulnerabilities, such as in-process memory isolation extension (IMIX), CURE, capability hardware enhanced reduced-instruction-set computing (RISC) instructions (CHERI), Sanctum, and Advanced RISC Machines (ARM) memory tagging extension (MTE). These methods provide isolation between processes in different levels of security and protect the system against most known memory-related vulnerabilities. However, they are mostly limited to architectural leakages and overlook microarchitectural information leakages, including processors and coprocessors internal buffers. ${}^{3,4,5}$

2. mitigation approaches based on microarchitec-tural vulnerabilities, such as CHUNKED-CACHE. While CHUNKED-CACHE can provide a secure cache by isolating different users' cache lines, it is focused on the specific microarchitectural memory component, i.e., cache, and does not cover other memory components in the SoC. ${}^{2}$

Due to the limitations of mitigation approaches in preventing new vulnerabilities, which we will explain in detail in the following sections, it is crucial to have vulnerability detection techniques. However, unlike software vulnerabilities that can be digitally patched, hardware patches often require physical modifications or replacements. Consequently, it is crucial to detect these vulnerabilities proac-tively before the fabrication. ${}^{1}$ Existing hardware memory vulnerability detection approaches can be broadly divided into static and dynamic techniques.

1. Static techniques, such as formal verification, analyze hardware without requiring execution to identify potential vulnerabilities. However, these methods often face state-explosion problems, particularly for complex and large-scale hardware designs like processors and SoCs.

2. Dynamic techniques, such as hardware fuzzing, monitor hardware behavior during the execution of crafted testates to detect memory vulnerabilities.6,7,8,9,10,11,12,13,14,15

Unlike static techniques, dynamic techniques are scalable to large designs, as we will explore in this article. ${}^{6}$

Recently, hardware fuzzing has gained prominence as an effective dynamic vulnerability detection technique. It has emerged as a promising tool for identifying vulnerabilities in large-scale designs, especially those that may be overlooked by traditional detection and mitigation approaches, including issues related to memory. An illustrative example of the efficacy of hardware fuzzing is the discovery of the Zenbleed memory vulnerability in AMD's Zen 2 microarchitecture, which was successfully detected using hardware fuzzing techniques. Moreover, a noteworthy observation is that memory-related vulnerabilities constitute a substantial portion of the vulnerabilities identified by state-of-the-art hardware fuzzers in open source processors or SoCs. ${}^{6,7,8,9,{10},{11},{12},{13},{14},{15}}$ For instance, 36% of vulnerabilities detected by the hardware fuzzer TheHuzz rooted in hardware-level memory. ${}^{6}$ This highlights the potential of hardware fuzzing in uncovering memory-related vulnerabilities that other mitigation and detection approaches might overlook.

In this article, we focus on hardware-related memory-safety issues and investigate the efficacy of innovative techniques, such as hardware fuzzing, in preemptively identifying vulnerabilities prefabrication. We will systematically review established hardware fuzzing techniques, explain how they overcome the limitations of existing memory-related vulnerability detection methodologies, and investigate their effectiveness in identifying memory-related vulnerabilities. We compare various hardware fuzzing techniques, highlighting their unique strengths and weaknesses in detecting hardware-level memory vulnerabilities. Afterward, we analyze and explain why hardware fuzzing has the potential to detect particular memory vulnerabilities overlooked by other methods. In conclusion, this article will present potential directions for the future development of hardware fuzzers to enhance their capabilities in memory safety verification.

## Background

## Memory Safety in Software

Memory safety vulnerabilities in software are inherent flaws that emerge within the software itself or the software platform that runs it, such as the operating system or firmware. Many vulnerabilities commonly originate from unsafe programming languages such as $\mathrm{C}$ and C++, while favored for system-level programming due to their efficiency and direct memory access. However, these languages have security-critical shortcomings, such as weak typing and low-level memory management. Consequentially, memory errors include spatial and temporal errors, often resulting in memory corruption attacks such as use-after-free, out-of-bounds access, and heap/stack overflow. Exploiting these vulnerabilities allows unauthorized access to sensitive information and jeopardizes the integrity of computing systems.

Therefore, addressing memory vulnerabilities is crucial to fortifying software security. Several tools have been developed to identify and rectify memory errors across the software development lifecycle. Static analysis tools scrutinize source code before execution, aiding in early vulnerability detection; however, their comprehensiveness across diverse scenarios remains a significant challenge as code complexity increases. In contrast, dynamic analysis tools track memory access and incorporate code to detect errors during runtime. However, their implementation can impact application performance and memory usage, particularly in real time or high-performance applications. For example, the utilization of AddressSanitizer can decrease performance by ${73}\%$ and increase memory consumption by ${3.4} \times$ , attributable to additional code for runtime analysis.

To address these challenges, recent research has investigated hardware-based approaches to enhance memory safety, such as CHERI, IMIX, ARM pointer authentication code, and intel control-flow enforcement technology. These technologies aim to isolate distinct memory regions or objects, preventing unauthorized access and minimizing the impact of various memory-related vulnerabilities such as buffer overflows, stack smashing, and heap-based vulnerabilities. Implementing security features at the hardware level often incurs less overhead than dynamic analysis tools. However, integrating these hardware-based solutions necessitates adaptation across existing software architectures and systems, posing significant implementation challenges. Achieving compatibility and seamless integration across diverse software platforms remains a pertinent concern in the adoption of these hardware-based memory safety solutions. ${}^{3,5}$

Besides, hardware-level defense mechanisms have been developed and implemented to mitigate software vulnerabilities, including address space layout randomization, data execution prevention, and control flow integrity. These techniques collectively provide an additional layer of protection by leveraging hardware-based features to fortify software and raise the complexity level for potential attackers. Nevertheless, they often necessitate hardware support, making deployment and adoption challenging, particularly for legacy systems lacking the required hardware features.

## Memory Safety in Hardware

Recent discoveries of various hardware vulnerabilities have challenged the traditional assumption that system security solely relies on secure software practices. Memory errors extend beyond software, encompassing hardware vulnerabilities that significantly influence overall system security. Analyzing memory safety through a hardware lens requires delving into various levels of abstraction and threat models. In this context, memory safety is broadly classified into two principal domains: architectural memory safety and microarchitectural memory safety.

Architectural memory safety. This encompasses bugs, vulnerabilities, and mitigation strategies that directly impact the processor's architectural state. These issues are directly observable and can be addressed through architectural modifications. Architectural memory safety issues often stem from flaws in the processor's instruction set architecture (ISA) or the memory management unit (MMU). These issues can lead to memory access errors, such as out-of-bounds memory access or unauthorized memory access. Mitigation strategies for architectural memory safety issues typically involve ISA modifications, MMU enhancements, or compiler-based techniques.

One prominent example of a hardware memory vulnerability is Rowhammer which specifically affects DRAM. Rowhammer operates by repeatedly accessing specific rows of memory, inducing electrical interference that causes bit flips the values of adjacent memory cells. This can lead to unauthorized data access and system-level compromises including tampering with cryptographic keys, escalation of privileges, and causing denial-of-service attacks. Different mitigation techniques are proposed to mitigate Rowhammer; among these, error-correcting codes utilize additional data bits to detect and rectify bit flips caused by Rowhammer, thereby fortifying memory integrity and minimizing the impact of such vulnerabilities.

Another recent notable example is the Reptar ${}^{3}$ vulnerability which was detected through fuzzing. Researchers found that adding redundant prefixes, i.e., rex. $\mathbf{r}$ , to fast short repeat move-optimized repeating move operation, i.e., rep movsb, will lead the processor to an unstable state; as a result, branches jump to unexpected locations. This abnormality may lead to system crashes, hangs, and information leaks, even from unprivileged guest virtual machines. Intel fixed this vulnerability by providing a microcode update.

Microarchitectural memory safety. This deals with bugs and vulnerabilities that are not directly visible at the architectural level and require side-channel techniques to reveal their impact. Microarchitectural memory safety issues arise from implementation and design flaws in the processor's microarchitecture. These issues can manifest in various ways, such as cache side-channel attacks or speculative execution attacks. Mitigating microarchitectural memory safety issues often involves microarchitectural modifications, such as speculative execution hardening and cache isolation techniques.

Notable examples of instances that highlight critical microarchitectural memory safety issues are Downfall and Zenbleed, which are transient execution vulnerabilities that were released in 2023 affecting Intel and AMD processors, respectively.

Downfall leverages the gather instruction within Intel ISA, bypassing previously implemented hardware fixes and security updates for transient execution-based vulnerabilities. The gather instruction family, an optimization designed to access scattered data in memory addresses, employs a shared buffer within a physical core. However, this shared buffer becomes vulnerable, potentially exposing the content of prior or concurrent executions of gather instructions within the transient window. Exploiting this vulnerability could enable malicious actors to extract sensitive information.

Zenbleed exploits the zeroing register optimization, i.e., the vzeroupper instruction in AMD processors. The vzeroupper instruction aids processors in mitigating redundant register dependencies. However, a victim process executing the vzeroupper instruction within a mispredicted speculative window leaves the register undefined. Subsequently, other processes may access the undefined register, which contains random data from the victim process. As all processes share the register file, attackers can read registers from other processes, potentially compromising sensitive information and threatening system security. Patches to these two bugs have been provided by Intel and AMD, respectively.

Architectural mitigation strategies from industry and academia, such as ARM MTE, AMD SEV, Intel's TDX, Santum, Keystone, and CURE, have played a crucial role in fortifying system security against known memory-related vulnerabilities. ${}^{4}$ These approaches primarily target architectural memory vulnerabilities and create isolation between processes of varying security levels. However, their effectiveness is limited as they do not consider micro-architectural vulnerabilities, leaving potential security gaps unaddressed. Microarchitectural mitigation methods, like CHUNKED-CACHE, are more targeted and focus on protecting specific memory parts like caches. Nevertheless, these methods do not cover all microarchitectural memory elements within the hardware. ${}^{2}$

Given the complexity of providing patches for newly discovered hardware vulnerabilities, there has been a noticeable shift toward presilicon detection methodologies. Static vulnerability detection techniques, such as formal verification, gained attention initially. However, these methods encounter significant challenges, such as state-explosion issues, especially in complex hardware structures like processors and SoCs. Consequently, dynamic vulnerability detection techniques, particularly hardware fuzzing, have emerged. Hardware fuzzing involves the execution of test cases to monitor hardware behavior and identify memory vulnerabilities actively. Unlike static methods, hardware fuzzing exhibits better scalability. Moreover, hardware fuzzing has emerged as a promising tool in efficiently identifying vulnerabilities in extensive designs that traditional detection and mitigation approaches may overlook, particularly those associated with memory, for instance, the detection of Zenbleed.

In this article, we aim to investigate the efficacy of hardware fuzzing in detecting and mitigating hardware memory vulnerabilities.

## Hardware Fuzzing for Memory Safety

Fuzzing is a dynamic technique widely used to discover coding errors and security holes. It involves providing invalid, unexpected, or random data as inputs to a design. The main goal is to observe the design's response and identify abnormal results that are potentially caused by vulnerabilities. Fuzzing operates under the premise that unexpected or edge-case inputs can lead to unanticipated behavior, exposing vulnerabilities that standard testing might overlook. We highlight the advantages of using hardware fuzzers for memory safety next.6,7,8,9,10,11,12,13,14,15

## Advantages of Hardware Fuzzers

Hardware fuzzing offers several distinct advantages over other approaches.

Automation. Unlike static techniques, hardware fuzzing does not require manual code inspection or manually written security properties. Hardware fuzzers automatically generate inputs, execute them on the design under test (DUT), collect activity in the DUT, analyze the output of the DUT, and flag potential vulnerabilities in the DUT. This automation significantly reduces the time and effort required to identify memory safety issues.

Compatibility. Hardware fuzzers can fuzz the DUTs both in the presence and absence of DUT source codes. Hardware fuzzers using industrial verification tools can easily integrate into the existing industrial verification flow. This compatibility enables the detection of memory safety vulnerabilities at both pre- and postsili-con phases with minimal false positives.

Efficiency. Hardware fuzzers generate unexpected inputs aiming to explore unanticipated behaviors of a design. Such generation of inputs ensures fast and efficient exploring of a wide range of execution paths and design spaces. This comprehensive coverage increases the likelihood of uncovering hidden vulnerabilities. Moreover, the inputs not only discover but also ensure the reproducibility of the vulnerabilities, which helps engineers identify the root cause of vulnerabilities.

Scalability. Hardware fuzzing can be adapted to larger, more complex, or diverse hardware systems than formal verification while maintaining or improving the efficiency and effectiveness of vulnerability detection. As hardware systems become more complex, the state space that needs to be verified exponentially increases. This makes hardware fuzzing more applicable for memory safety in modern systems.

Though hardware fuzzing cannot guarantee the completeness of verification and the absence of vulnerabilities, its automation, compatibility, efficiency, and scalability make it a promising strategy for verifying memory safety in modern, complicated systems.

## Hardware Fuzzers Workflow

We explain the general working flow of hardware fuzz-ers in this section.

Figure 1 shows the core components of a hardware fuzzer: a seed generator, input corpus, mutator, coverage feedback, DUT, and vulnerability detector. The seed generator O generates an initial set of inputs called seeds 2 either manually or randomly. The fuzzer runs the DUT 4 with these inputs $\mathbf{Q}$ , collects coverage $\mathbf{Q}$ , and mutates all "interesting" inputs (i.e., inputs that achieve coverage) using its mutator 8 to generate new inputs and store them in the input corpus Q. Mutators are data manipulation operations, such as bit-flip, byte-flip, clone, and swap. The vulnerability detector6reports any vulnerabilities detected during the execution. The fuzzer executes these new inputs and repeats the cycle until it achieves the desired coverage. Next, we explain the various components and tasks performed by hardware fuzzers.

DUT. DUT is a hardware design at either the pre- or post-silicon stage. The former provides source codes written in hardware description languages like Verilog and Sys-temVerilog, hardware construction languages like Chisel, or high-level synthesis like C. Hardware fuzzers use simulation tools like Verilator, Synopsys VCS, and Siemens Modelsim to simulate or use field-programmable gate arrays (FPGAs) to emulate DUTs. A DUT at the post-silicon stage is a fabricated hardware chip.

Coverage feedback. Based on the availability of source codes, hardware fuzzers can be classified as white-box and black-box fuzzers and measure various types of hardware behaviors as coverage feedback. Coverage points are assigned to each of these behaviors. For example, in white-box fuzzing, branch coverage indicates whether the different paths of a branch statement are covered or not. Whenever a design enters one of the branch paths, its corresponding coverage point is considered covered; otherwise, it remains uncovered. While, in black-box fuzzing, due to the lack of source codes, outputs of a DUT are used as coverage feedback. When fuzzing commercial processors, Google uses hardware performance counters (HPCs) as coverage feedback to detect the Zenbleed vulnerability.

Vulnerability detection. Unlike software, hardware does not have events like crashes, memory leaks, and buffer overflows to flag vulnerabilities. Instead, vulnerability detection in hardware fuzzers involves either assertion checking or differential testing.6,7,8,9,10,11,12,13,14,15

![0196f2ce-ab6a-762f-b736-bd531132bc1c_4_321_1681_1282_468_0.jpg](images/0196f2ce-ab6a-762f-b736-bd531132bc1c_4_321_1681_1282_468_0.jpg)

Figure 1. Hardware fuzzing framework.

In assertion checking, verification engineers insert the conditions to trigger the vulnerabilities or assertion properties into the DUT based on its specification and use the violations of these assertions during the simulation to detect vulnerabilities. However, assertion checking requires access to source code and is only applicable to white-box fuzzing. Moreover, assertion checking requires a specification for memory safety and hence cannot detect unknown vulnerabilities.

In differential testing, hardware fuzzers compare the outputs of the DUT and a golden reference model (GRM), tested with the same input, to detect vulnerabilities.6,7,8,9,10,12,13,14Differential testing can be applied at both presilicon and postsilicon stages. Also, since it does not require writing assertions, it can detect unknown vulnerabilities. GRMs are designed at a higher abstraction level to avoid vulnerabilities and, hence, generate expected outputs; any mismatches between a DUT's and a GRM's outputs reveal potential vulnerabilities in the DUT. For example, when fuzzing a processor, hardware fuzzers compare the processor's architecture states (e.g., values of general-purpose registers, memory, and so on) with the corresponding states of an ISA simulator. The mismatches between the processor's and simulator's outputs represent potential vulnerabilities in the processor.

## Existing Hardware Fuzzers

Several hardware fuzzing techniques have been developed to promote architectural memory safety at the presilicon stages. We categorize existing hardware fuzz-ers based on input generation, configuration, platform, and vulnerability detection, as shown in Table 1.

Input generation. Hardware fuzzers use various seed generation and mutation mechanisms, such as randomly generating seeds and using predefined mutators to generate subsequent inputs. TheHuzz, PSOFuzz, MABFuzz, RFUZZ, DIFUZZRTL, and SoCFuzzer use this strategy.6,7,8,9,11,12,15However, it is hard to trigger advanced optimization features in processors, such as speculative execution, by randomly generating instructions, as precise instruction order is crucial for triggering these advanced functionalities. Also, there is a deficiency in data and control flow entanglement. For instance, the data loaded by a load instruction may never be used by subsequent instructions. These two limitations constrain the capability of these hardware fuzzers to achieve high coverage and discover complex vulnerabilities, especially those related to memory.

To address these limitations, fuzzers use user-defined seed generation and mutation templates. The template divides an input into different testing blocks, aiming to explore various functionalities of the processor. For example, MorFuzz develops templates based on the functions of instructions. ${}^{13}$ A seed will contain multiple testing blocks following different templates. MorFuzz then applies mutators specialized for each template to generate new inputs. Similarly, Cascade steers the control flow of testing blocks to make an input execute longer. Cascade clusters instructions based on their functionalities, selects instructions, and constrains their operands' values so that the execution of the input will either terminate or continue. ${}^{14}$

However, creating user-defined templates manually requires experts knowledgeable about processor functions, a time-consuming and error-prone process. Chat-Fuzz, on the other hand, uses large language models (LLMs) to understand machine language, encompassing machine codes, ISA instructions, and their potential combinations. Subsequently, it generates complex test cases with entangled data and control flow. ChatFuzz achieves the same coverage as state-of-the-art hardware fuzzers but does so ${30} \times$ faster. Furthermore, Chat-Fuzz demonstrates its ability to trigger more complex features, such as the order of memory exceptions and atomic memory operations. ${}^{10}$

Table 1. Summary of existing hardware fuzzers.

<table><tr><td>Method</td><td>Input Generation</td><td>Configuration</td><td>Platform</td><td>Vulnerability Detection</td></tr><tr><td>TheHuzz ${}^{6}$</td><td>Stochastic</td><td>Static</td><td>Simulator</td><td>Differential testing</td></tr><tr><td>HyPFuzz7</td><td>Formal-assisted</td><td>Static</td><td>Simulator</td><td>Differential testing</td></tr><tr><td>${\mathsf{{PSOFuzz}}}^{8}$</td><td>Stochastic</td><td>Dynamic</td><td>Simulator</td><td>Differential testing</td></tr><tr><td>MABFuzz9</td><td>Stochastic</td><td>Dynamic</td><td>Simulator</td><td>Differential testing</td></tr><tr><td>ChatFuzz ${}^{10}$</td><td>LLM-assisted</td><td>Static</td><td>Simulator</td><td>Differential testing</td></tr><tr><td>RFUZZ11</td><td>Stochastic</td><td>Static</td><td>FPGA</td><td>Assertion checking</td></tr><tr><td>DIFUZZRTL ${}^{12}$</td><td>Stochastic</td><td>Static</td><td>FPGA</td><td>Differential testing</td></tr><tr><td>MorFuzz13</td><td>Template</td><td>Static</td><td>Simulator</td><td>Differential testing</td></tr><tr><td>Cascade14</td><td>Template</td><td>Static</td><td>Simulator</td><td>Differential testing</td></tr><tr><td>SoCFuzzer15</td><td>Stochastic</td><td>Static</td><td>FPGA</td><td>Assertion checking</td></tr></table>

www.computer.org/security

Similar to stochastic processes in other fields, the aforementioned fuzzers often have a low probability of generating inputs for logic requiring specific conditions-namely, the hard-to-reach design spaces of a fuzzer. Memory access usually requires hardware to be in a specific privileged state. Failing to verify this logic leaves opportunities for severe memory vulnerabilities. To tackle this limitation, HyPFuzz combines formal verification with fuzzing, establishing a hybrid hardware fuzzer. ${}^{7}$ Formal tools are used to generate seeds that explore hard-to-reach design spaces. These seeds then lead the fuzzing process to explore the hard-to-reach design spaces further.

Configuration. This category classifies fuzzers based on how they schedule the seed generation and mutation for the next iteration. Fuzzers with static configuration use constant probability distributions for selecting instructions (during seed generation) and mutators (during input mutation), irrespective of the design space explored or vulnerabilities detected. The static configuration, however, slows the coverage achievement and reduces the fuzzer's efficiency in detecting vulnerabilities. To overcome this limitation, PSOFuzz uses particle swarm optimization (PSO) to dynamically identify the optimal mutators and instruction opcodes for seed generation. ${}^{8}$ Similarly, ${MABFuzz}$ uses the multiarmed bandit (MAB) algorithms to select seeds with the potential to generate more "interesting" inputs. ${}^{9}$ PSOFuzz and MABFuzz detect existing vulnerabilities faster than the base-fuzzers they use with static configurations.

Platform. Hardware fuzzers detect vulnerabilities by executing DUTs on different platforms. FPGA emulation facilitates faster execution than register-transfer level (RTL) simulation but cannot generate code coverage like RTL simulators. RFUZZ introduces an FPGA framework for hardware fuzzing, featuring a coverage metric that monitors the toggling of the select signal of each 2:1 multiplexer. 11 However, the instrumentation overhead of RFUZZ limits its deployment on complex processors. DIFUZZRTL simplifies RFUZZ's coverage metric by monitoring the toggling of control registers. However, DIFUZZRTL's coverage metric still introduces high instrumentation overhead as the size and number of control signals increase, limiting its scalability. Moreover, the coverage metric monitors partial combinational logic in hardware, leaving spaces for vulnerabilities. ${}^{12}$ SoCFuzzer introduces an FPGA framework to verify SoC designs. ${}^{15}$ However, it relies on the coverage of input and output spaces for feedback to guide input generation, which does not directly reflect design space exploration.

Fuzzers based on RTL simulators use intrinsic code coverage metrics as feedback. For example, TheHuzz leverages coverage metrics from commercial simulators, such as Synopsys ${VCS}$ to guide the fuzzer. These coverage metrics include branch, finite-state machine, and toggle, to monitor both combinational and sequential logic in hardware, guiding TheHuzz to explore design spaces and detect vulnerabilities exhaustively. ${}^{6}$ However, their simulations are not as fast as FPGA emulation.

Vulnerability detection. Existing hardware fuzzers apply either assertion checking or differential testing to detect vulnerabilities. RFUZZ and SoCFuzzer apply assertion checking and can only detect vulnerabilities that violate security specifications or known conditions. ${}^{{11},{15}}$ DIFUZZRTL and TheHuzz deploy GRMs to detect previously unknown vulnerabilities on processors by differential testing. ${}^{6,{11}}$ However, the differential testing results contain many false positives due to the differences between the setup of GRMs and simulation environments, such as the memory allocation of stack and heap. Also, due to the massive amount of inputs, identifying the specific sequences of instructions that cause vulnerabilities is difficult. MorFuzz reduces the false positives of differential testing by synchronizing the setup of GRMs and simulation environments. Cascade identifies the minimal sequence of instructions that cause a vulnerability by systematically omitting instructions until the instruction sequence controlling the vulnerability behavior is detected. ${}^{{13},{14}}$

## Hardware Memory Vulnerabilities Identified by Hardware Fuzzers

Existing fuzzers detected numerous memory-related vulnerabilities by fuzzing popular open source RISC-V processors. We now discuss some of these vulnerabilities and describe how these vulnerabilities in hardware can be exploited through software.

FENCE.I instruction vulnerability. This is a vulnerability in the RISC-V ISA-based CVA6 processor, where the decoder of the processor fails to identify critical, memory management-related FENCE.I instructions. This vulnerability is caused by the incorrect implementation of decoding logic for the FENCE.I instruction and is similar to the expected behavior violation vulnerability, CWE-440. The implementation of the decoder module in the CVA6 processor includes additional and incorrect constraints when detecting the FENCE.I instruction. As a result, the CVA6 processor fails to recognize some of the valid FENCE.I instructions with nonzero values in its imm and rs1 fields.

The RISC-V ISA requires programs to use FENCE.I instructions when performing memory-critical operations, such as updating instruction memory to ensure cache coherence in the processor. The hardware performs actions such as flushing the instruction pipeline and cache lines to achieve cache coherence. Thus, this vulnerability makes even a memory-safe software program (that uses FENCE.I instructions) vulnerable to memory-safety attacks due to cache incoherence.

Triggering this vulnerability requires verifying the processors with different operand values for the FENCE.I instruction. Formal verification is impractical due to the vast number of instructions and operand values defined in the RISC-V ISA, making it difficult to verify all possible assertions. ${}^{6,7}$ In contrast, fuzzers are better suited for detecting such vulnerabilities as they employ mutation techniques to vary instruction operand values.

Cache coherency vulnerability. Existing fuzzers detected another memory-related vulnerability related to the cache coherency in the CVA6 processor. This issue arises when the software program modifies instruction memory, and the processor fails to use updated instructions when executing from the modified memory location, contrary to RISC-V specification expectations. The vulnerability stems from the CVA6 processor not having hardware mechanisms to detect or prevent memory incoherence, relying instead on software to use FENCE.I instructions for memory safety operations. While the ISA specification does not require hardware to ensure memory safety in this scenario, it is recommended that hardware implementation also include memory-safety checks for instances when either the software programs miss the FENCE.I instruction or when the FENCE.I instruction is implemented incorrectly in hardware (such as in the case of the vulnerability discussed previously). Failing to have such memory-safety mechanisms in hardware can lead to the execution of incorrect instructions and cause memory and storage vulnerability, CWE-1202. ${}^{6,7,{10}}$

Triggering this vulnerability involves verifying the processor with memory-sensitive operations like overwriting instruction memory. Fuzzers are effective in identifying these vulnerabilities due to their random instruction generation and mutation, capable of creating programs to modify instruction memory.

Register value vulnerability. This is a severe memory safety vulnerability in the CVA6 processor that returns unknown/random values when accessing the values of control and status registers (CSRs). Such registers can be HPCs. Designers widely use this type of register to identify the performance bottleneck of programs and detect malware. It is a cross-module vulnerability that a module controlling the access of the CSRs assumes there are 32 registers. In comparison, another module storing the values of the CSRs only allocates 16 registers. When a program accesses a CSR with no corresponding register, the processor returns unknown/random values. This vulnerability ${}^{4}$ resulted in CVE-2022-3302 and can be categorized in CWE-1281 because the unknown/ random value will cause unexpected memory behaviors in processors.

This vulnerability is difficult to detect by nonhybrid fuzzing techniques because fuzzing alone has a low probability of generating inputs to access the correct CSR. At the same time, formal verification alone faces the state explosion issue from exploring all CSRs. HyPFuzz detected this vulnerability using a formal tool to generate an input that accesses one CSR and then using the fuzzer to mutate the input to access the rest of the CSRs. ${}^{7}$

## Discussion and Future Direction

Hardware fuzzing, while promising, presents substantial challenges and gaps in current methodologies that must be addressed.

Academic hardware fuzzers commonly utilize open source hardware and processors as benchmarks. However, the absence of industry-level standards means that current open source processors lack specific advanced functionalities like optimization buffers and trusted execution environments. Consequently, open source designs may not accurately represent real-world processors and SoCs. Some hardware fuzzers, e.g., Cascade, are reporting the detection of functional bugs and security vulnerabilities in outdated and decommissioned open source processor implementations, e.g., Kronos RISC-V and PicoRV32, rendering them irrelevant to industry standards. It's important to note that a key advantage of hardware fuzzers lies in their ability to assess advanced, complex, and real-world scale processors. Thus, utilizing simple and small designs as benchmarks to demonstrate hardware fuzzer effectiveness is understating the potential of hardware fuzzing. In cases involving small designs, alternative methodologies, such as formal methods, can offer superior assurances and coverage.

Indeed, we witnessed this gap between industry-standard full-fledged processors/SoCs and the open source hardware in the world's largest SoC security competition, Hack@EVENT, a joint academia-industry collaboration since ${2018}^{5}$ The competition requires teams from both industry and academia to detect and analyze real-world hardware vulnerabilities that are deliberately injected into open source SoC design. These vulnerabilities are emulated and inspired by the hardware common weakness enumeration (CWE) from MITRE Corporation, which can serve as a benchmark for evaluating security tools and establish a foundational reference for identifying, mitigating, and preventing security vulnerabilities. Additionally, to enhance the representativeness of CWEs, we provide demonstrative examples for hardware CWEs in collaboration with the MITRE Corporation. ${}^{6}$

Hence, to develop a hardware fuzzer aligned with industry standards, researchers must rigorously evaluate their hardware fuzzers against the most complex open source processors with active communities like BOOM and try to identify bugs representing different types of CWEs. One good mature benchmark would be Hack@EVENT benchmarks, a comprehensive set of industry-standard vulnerabilities in hardware for system security research, to democratize the hardware security research for detecting vulnerabilities; without these testbeds, only elite companies who design real-world design can evaluate their security evaluation tools.

Through systematic analysis of existing hardware fuzzers and careful consideration of the capabilities inherent in hardware fuzzing, we have identified potential research directions to advance hardware fuzzing for memory safety.

## Vulnerability Detection

The efficacy of vulnerability detection within the hardware fuzzing framework relies on identifying discrepancies from comparing execution traces derived from simulating the hardware against those from the hardware's GRM.

However, this vulnerability detection mechanism possesses the following limitations.

Discrepancies versus vulnerabilities. Discrepancies do not necessarily indicate vulnerabilities. Hence, certain deviations from expected behavior, as specified by GRM, may arise due to the flexibility defined in the ISA specification. ${}^{10}$ These mismatches increase false positives within the detection mechanism, thereby augmenting the manual workload associated with vulnerability detection.

GRMs versus microarchitectural behaviors. GRMs fall short in accurately capturing the design undertest, the primary root cause for recent critical vulnerabilities, particularly those associated with memory. This limitation underscores the necessity to explore microarchitectural behaviors for vulnerability detection, offering the potential for hardware fuzzers to identify more severe vulnerabilities, including those related to advanced features such as transient execution and buffer optimizations. A plausible approach to addressing this limitation involves integrating information flow tracking techniques alongside hardware fuzzing to identify microarchitectural memory vulnerabilities.1,2,6,7,8,9,10,11,12,13,14

Golden model versus no golden model. The absence of a GRM is a recurrent challenge, particularly evident in the open source community, where an SoC with identical peripherals may lack a corresponding golden model. Consequently, developing a fuzzer that operates independently of a GRM seems imperative.

## Pinpointing the Vulnerability

Current hardware fuzzing frameworks cannot identify the root cause of the vulnerability within the design, i.e., its location in the hardware design. The expansive code space in large hardware designs, such as processors and SoCs, poses a significant challenge in pinpointing the source of a vulnerability. This task requires manual intervention and an in-depth comprehension of the microarchitectures underlying the design. An idea to explore is the integration of information flow tracking (IFT) techniques into hardware. IFT is a methodology that observes the flow of information within hardware registers and modules. So, upon detecting a vulnerability during the fuzzing process, the hardware fuzzer can utilize the information provided by the IFT process to trace back the leaked information back to its root cause.

## Hardware Fuzzing for SoC

In contrast to individual processors or standalone hardware designs, there is a compelling need to enhance hardware fuzzers to validate SoC designs. This necessity arises because SoCs are more complicated than processors, which may have many vulnerabilities.

The peripheral components within SoCs encompass diverse memory modules, including read-only memory, primary memory, numerous internal buffers, and secure FUSE memory designed to resist tampering. These memory modules store sensitive information, such as boot sequence instructions, private user data, and cryptographic keys. Additionally, SoCs incorporate specialized coprocessors like graphics processing units, AI accelerators, direct memory access (DMA) controllers, cryptographic accelerators, and communication modules. These coprocessors play pivotal roles in executing computations involving sensitive data stored in memory components, such as cryptographic operations performed by crypto-accelerators, data transfers facilitated by DMA, and the training of machine learning models using AI accelerators.

Despite the implementation of various security mechanisms in modern SoCs, including fabric access control, control register locks, memory isolation, and secure debugging, there remain limitations to these security measures. Considering inherent constraints associated with postsilicon hardware patching and hardware fuzzing results in detecting hardware-level memory vulnerabilities in complex designs, making hardware fuzzing a high-potential candidate for SoC security verification.

I$\mathrm{n}$ this article, we focused on hardware-related memory-safety issues and explored the efficacy of innovative techniques, specifically hardware fuzzing, in preemptively identifying prefabrication vulnerabilities. We have highlighted their strengths and weaknesses in detecting memory vulnerabilities by systematically reviewing existing hardware fuzzing techniques. The analysis indicates that hardware fuzzing has the potential to reveal specific memory vulnerabilities overlooked by other methods. This article not only contributes to the understanding of hardware-related memory safety but also presents potential directions for the future development of hardware fuzzers to enhance their capabilities in memory safety verification for addressing the evolving landscape of hardware vulnerabilities and ensuring the overall security of computing systems.

## Acknowledgment

Our research work was partially funded by Intel's Scalable Assurance Program, Deutsche Forschun-gsgemeinschaft (DFG)-SFB 1119-236615297, the European Union under Horizon Europe Programme-Grant Agreement 101070537-CrossCon, the European Research Council under the ERC Programme-Grant 101055025-HYDRANOS, the US Office of Naval Research (ONR Award #N00014-18-1-2058), and the Lockheed Martin Corporation. This work does not in any way constitute an Intel endorsement of a product or supplier. Any opinions, findings, conclusions, or recommendations expressed herein are those of the authors and do not necessarily reflect those of Intel, the European Union, the European Research Council, the US Government, or the Lockheed Martin Corporation.

## References

1. G. Dessouky et al., "HardFails: Insights into software-exploitable hardware bugs," in Proc. 28th USENIX Secur. Symp., 2019, pp. 213-230, doi: 10.5555/3361338.3361354.

2. G. Dessouky, A. Gruler, P. Mahmoody, A. Sadeghi, and E. Stapf, "Chunked-cache: On-demand and scalable cache isolation for security architectures," in Proc. NDSS Symp., 2022, pp. 1-18.

3. T. Frassetto, P. Jauernig, C. Liebchen, and A. Sadeghi, "IMIX: In-process memory isolation extension," in Proc. 27th USENIX Secur. Symp., 2018, pp. 83-97, doi: 10.5555/3277203.3277211.

4. R. Frassetto et al., "CURE: A Security architecture with customizable and resilient enclaves," in Proc. 30th USE-NIX Secur. Symp., 2021, pp. 1073-1090.

5. R.N.M.Watson et al., "CHERI: Ahybrid capability-system architecture for scalable software compartmentalization," in Proc. IEEE Symp. Secur. Privacy, 2015, pp. 20-37, doi: 10.1109/SP.2015.9.

6. R. Kande et al., "TheHuzz: Instruction fuzzing of processors using golden-reference models for finding software-exploitable vulnerabilities," in Proc. 31st USE-NIX Secur. Symp., 2022, pp. 3219-3236.

7. C. Chen et al., "HyPFuzz: Formal-assisted processor fuzzing," in Proc. 32nd USENIX Secur. Symp., 2023, pp. 1361-1378, doi: 10.5555/3620237.3620314.

8. C. Chen, V. Gohil, R. Kande, A. Sadeghi, and J. Rajen-dran, "PSOFuzz: Fuzzing processors with particle swarm optimization," in Proc. IEEE/ACM Int. Conf. Comput.-Aided Des., 2023, pp. 1-9, doi: 10.1109/ ICCAD57390.2023.10323913.

9. V. Gohil, R. Kande, C. Chen, A. Sadeghi, and J. Rajen-dran, "MABFuzz: Multi-armed bandit algorithms for fuzzing processors," in Proc. IEEE Des., Autom. Test Europe Conf., 2024, pp. 1-6.

10. M. Rostami, M. Chilese, S. Zeitouni, R. Kande, J. Rajen-dran, and A. Sadeghi, "Beyond random inputs: A novel ML-based hardware fuzzing," in Proc. IEEE Des., Autom. Test Europe Conf., 2024, pp. 1-6.

11. K. Laeufer, J. Koenig, D. Kim, J. Bachrach, and K. Sen, "RFUZZ: Coverage-directed fuzz testing of RTL on FPGAs," in Proc. IEEE/ACM Int. Conf. Comput.-Aided Des., 2018, pp. 1-8, doi: 10.1145/3240765.3240842.

12. J. Hur, S. Song, D. Kwon, E. Baek, J. Kim, and B. Lee, "DifuzzRTL: Differential fuzz testing to find CPU bugs," in Proc. IEEE Symp. Secur. Privacy, 2021, pp. 1286-1303, doi: 10.1109/SP40001.2021.00103.

13. J. Xu, Y. Liu, S. He, H. Lin, Y. Zhou, and C. Wang, "Mor-Fuzz: Fuzzing processor via runtime instruction mor-phing enhanced synchronizable co-simulation," in Proc. 32nd USENIX Secur. Symp., 2023, pp. 1307-1324, doi: 10.5555/3620237.3620311.

14. F. Solt, K. Ceesay-Seitz, and K. Razavi, "Cascade: CPU fuzzing via intricate program generation," in Proc. 33rd USENIX Secur. Symp., 2024, pp. 1-18.

15. M. Hossain, A. Vafaei, K. Z. Azar, F. Rahman, F. Farah-mandi, and M. Tehranipoor, "SoCFuzzer: SoC vulnerability detection using cost function enabled fuzz testing," in Proc. Des., Autom. Test Europe Conf., 2023, pp. 1-6, doi: 10.23919/DATE56975.2023.10137024.

Mohamadreza Rostami is a Ph.D. student in computer science at Technical University of Darmstadt, 64277 Darmstadt, Germany. His research interests include hardware security, hardware fuzzing, and microarchi-tectural vulnerabilities. Rostami received an M.Sc. in communication security and cryptography from the University of Tehran. Contact him at mohamadreza. rostami@trust.tu-darmstadt.de.

Chen Chen is a Ph.D. student in computer engineering at Texas A&M University, College Station, TX 77843 USA. His research interests include hardware security, hardware fuzzing, and formal verification. Chen received an M.S. in electrical engineering from the University of Wisconsin—Madison. He is a student member at ACM. Contact him at chenc@tamu.edu.

Rahul Kande is a Ph.D. student in computer engineering at Texas A&M University, College Station, TX 77843 USA. His research interests include hardware security and computer architecture, with a focus on developing hardware fuzzers to detect security vulnerabilities. Kande received a B.Tech. in electronics and communication engineering with a minor in computer science and engineering from the Indian Institute of Technology Guwahati. He is a Graduate Student Member of IEEE. Contact him at rahulkande@tamu.edu.

Huimin Li is a Ph.D. student in cyber security at Delft University of Technology, Delft, The Netherlands. Her research interests include hardware security, deep learning, and RISC-V. Li received a master's degree in micro-electromechanical systems from Northwestern Polytechnical University. Contact her at h.li-7@ tudelft.nl.

Jeyavijayan Rajendran is an associate professor in the Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX 77843 USA. His research interests include hardware security and computer security. Rajendran received a Ph.D. in electrical engineering from New York University. His research has won the NSF CAREER award, ACM SIGDA Outstanding Young Faculty award, IEEE CEDA Ernest Kuh Early Career award, Intel Security Academic Leadership award, and Office of Naval Research Young Investigator award. He is a Senior Member of IEEE. Contact him at jv.rajendran@tamu.edu.

Ahmad-Reza Sadeghi is a full professor of computer science at the Technical University of Darmstadt, 64277 Darmstadt, Germany. His research interests include hardware security, software security, and artificial intelligence security. Sadeghi received a Ph.D. in privacy-protecting cryptographic protocols and systems from the University of Saarland. He has received prestigious awards, among others, ACM SIGSAC, Intel Academic Leadership Award, European Research Council advanced grant, and German IT security. He is a Member of IEEE. Contact him at ahmad.sadeghi@trust.tu-darmstadt.de.

CALL FOR ARTICLES

![0196f2ce-ab6a-762f-b736-bd531132bc1c_10_893_1355_639_834_0.jpg](images/0196f2ce-ab6a-762f-b736-bd531132bc1c_10_893_1355_639_834_0.jpg)

- datacenter operations, - IT asset management, and - health information technology. We welcome articles accompanied by web-based demos. For more information, see our author guidelines at www.computer.org/itpro/author.htm. WWW.COMPUTER.ORG/ITPRO Digital Object Identifier 10.1109/MSEC.2024.3425119

